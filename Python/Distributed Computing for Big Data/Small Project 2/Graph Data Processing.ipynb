{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dIikFr7cAFkq"
   },
   "source": [
    "# ST446 Distributed Computing for Big Data\n",
    "## Assignment 2 - PART 1\n",
    "---\n",
    "\n",
    "**We highly recommend using GCP, as the data sets used are about 20 GB in total.** Alternatively, you can use your own computer.\n",
    "\n",
    "## P1: Querying the YAGO semantic knowledge base\n",
    "\n",
    "YAGO is a semantic knowledge base, derived from Wikipedia, WordNet and GeoNames (in its Version 1). YAGO contains knowledge about more than 10 million entities (like persons, organizations and cities) and contains more than 120 million facts about these entities. You may find more about YAGO [here](https://www.mpi-inf.mpg.de/departments/databases-and-information-systems/research/yago-naga/yago/#c10444).\n",
    "\n",
    "In this assignment, you are asked to use parts of the YAGO dataset to demonstrate your knowledge about Spark GraphFrames and motif queries. In particular, you are asked to **_use motif queries_** to find out answers to the following queries stated in English:\n",
    "\n",
    "**A (max points 10)**. _Politicians who are also scientists_ (sorted alphabetically by name of person)\n",
    "\n",
    "**B (max points 10)**. _Companies whose founders were born in London_ (sorted alphabetically by name of founder)\n",
    "\n",
    "**C (max points 10)**. _Writers who have won a Nobel Prize (in any discipline)_ (sorted alphabetically by name of person)\n",
    "\n",
    "**D (max points 10)**. _Nobel prize winners who were born in the same city as their spouses_ (sorted alphabetically by name of person)\n",
    "\n",
    "**E (max points 10)**. _Politicians that are affiliated with a right-wing party_ (sorted alphabetically by name of person)\n",
    "\n",
    "Please always show the first 20 entries of the resulting DataFrame and the total count of relevant entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fz6Fy6jfAFkr"
   },
   "source": [
    "---\n",
    "\n",
    "## 0.1 Get YAGO data\n",
    "\n",
    "* You will need to download the following datasets that are part of YAGO (see [here](https://www.mpi-inf.mpg.de/departments/databases-and-information-systems/research/yago-naga/yago/downloads/) for more information):\n",
    "\n",
    "    * A set of relationships between instances (for example, specifying that Emomali Rahmon is the leader of the Military of Tajikistan). Link: http://resources.mpi-inf.mpg.de/yago-naga/yago3.1/yagoFacts.tsv.7z\n",
    "\n",
    "    * A set of subclass relationships (for example, specifying that *A1086* is *a road in England*, or that *Salmonella Dub* is *a Reggae music group* and also a *New Zealand dub musical group*). Link: http://resources.mpi-inf.mpg.de/yago-naga/yago3.1/yagoTransitiveType.tsv.7z\n",
    "\n",
    "* Use `wget` to download the data into the master node of your Dataproc cluster (the files are big!).\n",
    "\n",
    "* Next, you will need to extract `tsv` files from the `7z` archives that you have downloaded. Use the following commands to install `p7zip` on your Dataproc cluster and extract the files. Please note that this can take a while, in particular as `yagoTransitiveType.tsv` is **18GB** large.\n",
    "\n",
    "* Put the files (`yagoTransitiveType.tsv` and `yagoFacts.tsv`) into the Hadoop file system. \n",
    "\n",
    "```\n",
    "wget http://resources.mpi-inf.mpg.de/yago-naga/yago3.1/yagoFacts.tsv.7z\n",
    "wget http://resources.mpi-inf.mpg.de/yago-naga/yago3.1/yagoTransitiveType.tsv.7z\n",
    "sudo apt-get install p7zip-full\n",
    "7z x yagoTransitiveType.tsv.7z \n",
    "7z x yagoFacts.tsv.7z\n",
    "hadoop fs -put ./ /yago\n",
    "```\n",
    "\n",
    "Also, have a look at their first few lines to understand what kind of data they contain (you need this to infer the schemas).\n",
    "\n",
    "```\n",
    "head yagoTransitiveType.tsv\n",
    "head yagoFacts.tsv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPkTqjAFAFks"
   },
   "source": [
    "## 0.2 Read the data into a Spark DataFrame\n",
    "\n",
    "Please load the data from `yagoFacts.tsv` into a DataFrame called `df` and `yagoTransitiveType.tsv` into a DataFrame called `df_subclasses`.\n",
    "\n",
    "Have a look at the beginning of the files to understand the schema. Once imported, both DataFrames should have columns labelled as `id`, `subject`, `predicate`, `object` and `value`.\n",
    "In the case of `yagoTransitiveType.tsv`, some of the predicates can be understood as *is a subclass of* or *is a member of the class*, and the objects can be understood as classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cJO_frZGAFkt"
   },
   "outputs": [],
   "source": [
    "# your code => remember to include the schema\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "yagotrans_path = 'hdfs://st446-cluster-m/yago/yagoTransitiveType.tsv'\n",
    "yagofacts_path = 'hdfs://st446-cluster-m/yago/yagoFacts.tsv'\n",
    "\n",
    "df_schema = StructType([\n",
    "    StructField(\"id\", StringType(), True),    \n",
    "    StructField(\"subject\", StringType(), True),\n",
    "    StructField(\"predicate\", StringType(), True),\n",
    "    StructField(\"object\", StringType(), True),\n",
    "    StructField(\"value\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "\n",
    "df_subclasses_schema = StructType([\n",
    "    StructField(\"id\", StringType(), True),    \n",
    "    StructField(\"subject\", StringType(), True),\n",
    "    StructField(\"predicate\", StringType(), True),\n",
    "    StructField(\"object\", StringType(), True),\n",
    "    StructField(\"value\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "df = spark.read.csv(yagofacts_path, header='false', schema=df_schema, sep='\\t')\n",
    "df.createOrReplaceTempView(\"df\")\n",
    "\n",
    "df_subclasses = spark.read.csv(yagotrans_path, header='false', schema=df_subclasses_schema, sep='\\t')\n",
    "df_subclasses.createOrReplaceTempView(\"df_subclasses\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5aQpS0hAFkt"
   },
   "source": [
    "## 0.3 Understand the database schema\n",
    "\n",
    "Let's look at the schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "DYvpJFWnAFku",
    "outputId": "d5eb7d89-e582-4096-d643-4a52a4e55b67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- subject: string (nullable = true)\n",
      " |-- predicate: string (nullable = true)\n",
      " |-- object: string (nullable = true)\n",
      " |-- value: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- subject: string (nullable = true)\n",
      " |-- predicate: string (nullable = true)\n",
      " |-- object: string (nullable = true)\n",
      " |-- value: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# your code\n",
    "df.printSchema()\n",
    "df_subclasses.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should be similar to that:\n",
    "\n",
    "```\n",
    "YAGO Facts schema:\n",
    "\n",
    "root\n",
    " |-- id: string (nullable = true)\n",
    " |-- subject: string (nullable = true)\n",
    " |-- predicate: string (nullable = true)\n",
    " |-- object: string (nullable = true)\n",
    " |-- value: double (nullable = true)\n",
    "\n",
    "YAGO TransitiveType schema:\n",
    "\n",
    "root\n",
    " |-- id: string (nullable = true)\n",
    " |-- subject: string (nullable = true)\n",
    " |-- predicate: string (nullable = true)\n",
    " |-- object: string (nullable = true)\n",
    " |-- value: double (nullable = true)\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULK0aipvAFku"
   },
   "source": [
    "The useful information is in columns `subject`, `predicate` and `object`. **predicate** defines the relation between entities **subject** and **object**. For example, for *Albert Einstein was born in Ulm*, `Albert Einstein` is the subject, `was born in` is the predicate and `Ulm` is the object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWlhiNH8AFkv"
   },
   "source": [
    "## 0.4 Simple query example\n",
    "\n",
    "To get information about where Albert Einstein was born, we can load data into Spark using the following queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "SZiOTz8aAFkv",
    "outputId": "eebcd600-e82a-4de1-a356-b832a493306f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+---------------+-----+\n",
      "|                  id|             subject|  predicate|         object|value|\n",
      "+--------------------+--------------------+-----------+---------------+-----+\n",
      "|<id_thPX9b1zg!_7f...|<William_Jones_(W...|<wasBornIn>|<Penrhiwceiber>| null|\n",
      "+--------------------+--------------------+-----------+---------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking for predicate `was born in`\n",
    "born_city_df = df.where(\"predicate == '<wasBornIn>'\")\n",
    "born_city_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "gPKj9hu3AFkw",
    "outputId": "b5cf2fea-3c1e-456b-abb5-b48f5b48ef72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+-----------+------+-----+\n",
      "|                  id|          subject|  predicate|object|value|\n",
      "+--------------------+-----------------+-----------+------+-----+\n",
      "|<id_sbCVliqDT2_7f...|<Albert_Einstein>|<wasBornIn>| <Ulm>| null|\n",
      "+--------------------+-----------------+-----------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking for subject\n",
    "born_city_df.where(\"subject = '<Albert_Einstein>'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k88MMFJ-AFkw"
   },
   "source": [
    "You may wonder how one would know whether to use the predicate '&lt;wasBornIn&gt;' or '&lt;was_born_in&gt;' and subject '&lt;Albert_Einstein&gt;' or '&lt;AlbertEinstein&gt;'. \n",
    "\n",
    "For YAGO subjects (and objects), the naming is aligned with Wikipedia. For example, Albert Einstein's wiki is: https://en.wikipedia.org/wiki/Albert_Einstein and you can see it is 'Albert_Einstein'. \n",
    "\n",
    "For predicates, you can look at the \"property\" list from the [Yago Web interface](https://yago-knowledge.org/) or the documentation on the TAXONOMY theme ([here](https://www.mpi-inf.mpg.de/departments/databases-and-information-systems/research/yago-naga/yago/downloads)).\n",
    "\n",
    "Try different queries with this Web interface query to understand more how to query YAGO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uLuSmGuAFkw"
   },
   "source": [
    "## 0.5 Simple motif example\n",
    "\n",
    "To find out \"Which city was Albert Einstein born in?\", we can use the following motif query on the first dataframe (`df`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "hOmxi3b1AFkx",
    "outputId": "5adb3f26-5c02-410c-fc16-4d67d96c9eee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-------+\n",
      "|                  a|                   e|      b|\n",
      "+-------------------+--------------------+-------+\n",
      "|[<Albert_Einstein>]|[<Albert_Einstein...|[<Ulm>]|\n",
      "+-------------------+--------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from graphframes import *\n",
    "\n",
    "# helper function to filter nodes (vertices) by subject and object, and establish edges\n",
    "def vertices_edges_split(df, condition):\n",
    "    sub = df.filter(condition).select(\"subject\").withColumnRenamed(\"subject\",\"id\")\n",
    "    obj = df.filter(condition).select(\"object\").withColumnRenamed(\"object\",\"id\")\n",
    "    v = sub.union(obj).distinct()\n",
    "    e = df.filter(condition).select(\"subject\",\"object\",\"predicate\")\\\n",
    "    .withColumnRenamed(\"subject\",\"src\").withColumnRenamed(\"object\",\"dst\")\n",
    "    return v, e\n",
    "\n",
    "# build a graph filtering by Albert Einstein\n",
    "v, e = vertices_edges_split(df, \"subject='<Albert_Einstein>'\")\n",
    "g = GraphFrame(v, e)\n",
    "# find all relationships where Albert Einstein is the subject...\n",
    "motifs = g.find(\"(a)-[e]->(b)\")\n",
    "# ... and the predicate is `was born in`\n",
    "res = motifs.filter(\"e.predicate='<wasBornIn>'\")\n",
    "res.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmd1E8UGAFkx"
   },
   "source": [
    "## 0.6 Some useful tips\n",
    "\n",
    "### Get a subset of YAGO database\n",
    "YAGO database is large, so we don't try to load the entire database into a dataframe and then query it. If you do this, you will find that you won't even be able to execute `df.take(1)`, as it would take up too much of space (at least on a laptop). Instead, you use Spark SQL commands or `df.where` to get a suitable fraction of the data.\n",
    "\n",
    "### Try the queries in the YAGO Web interface first\n",
    "It is sometimes tricky to get the right \"subject\", \"predicate\" and \"object\". It is easier if you start from [Yago Web interface](https://yago-knowledge.org/) rather than directly querying in PySpark. Once your query works, you can convert your query to PySpark code. \n",
    "\n",
    "Note that sometimes the Web version of object/subject code may be different from what you need to type here. For example, company code is &lt;wordnet_company_108058098&gt; when you do the query here but when you do it via the web interface it is &lt;wordnet company 108058098&gt;. \n",
    "\n",
    "### Be patient and don't do this exercise in the last minute\n",
    "Some trial and error is needed to get the query right and it may take some time get the result for a query. For these reasons, we advise you not to wait to work out this exercise just before the submission deadline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dcG2wA0eAFky"
   },
   "source": [
    "---\n",
    "\n",
    "## 1. Politicians who are also scientists (Question A)\n",
    "Find all politicians who are also scientists. Output top 20 of them. How many people are in the dataset who are both scientists and politicians?\n",
    "\n",
    "Please follow these steps:\n",
    "* Operate on the subsets of `df_subclasses` where the objects are `'<wordnet_scientist_110560637>` (scientists) and `'<wordnet_politician_110450303>'` (politicians), and where the predicates are `rdf:type`.\n",
    "* Use graphframes and the right parts of `df_subclasses` to construct a graph whose (directed) edges point from subjects to objects. Hence, its source vertices are subjects and it destination vertices are objects. It may be convenient to use intermediate DataFrames and join all the required dataframes of edges and vertices.\n",
    "* The subjects will be people and the objects will be classes (e.g., scientists, politicians).\n",
    "* Use a motif query to find all instances that fulfil the criteria specified in the question.\n",
    "* It is a good idea to define a function that takes a DataFrame and outputs a set of data frames for vertices and edges.\n",
    "\n",
    "Please sort the output alphabetically by the person column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# your code\n",
    "#Create a subset of the df_subclasses, where the object is scientist.\n",
    "df_sub_scientists = spark.sql(\"select * from df_subclasses where object == '<wordnet_scientist_110560637>'\")\n",
    "\n",
    "#Create a subset of the df_subclasses, where the object is politician.\n",
    "df_sub_politician = spark.sql(\"select * from df_subclasses where object == '<wordnet_politician_110450303>'\")\n",
    "df_sub_politician.createOrReplaceTempView(\"df_sub_politician\")\n",
    "\n",
    "#Union the dataframes of scientists and polticians in one\n",
    "df_sub_scien_polit = df_sub_scientists.union(df_sub_politician)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a graph filtering by predicate being rdf:type\n",
    "from graphframes import *\n",
    "\n",
    "# helper function to filter nodes (vertices) by subject and object, and establish edges\n",
    "def vertices_edges_split(df, condition):\n",
    "    sub = df.filter(condition).select(\"subject\").withColumnRenamed(\"subject\",\"id\")\n",
    "    obj = df.filter(condition).select(\"object\").withColumnRenamed(\"object\",\"id\")\n",
    "    v = sub.union(obj).distinct()\n",
    "    e = df.filter(condition).select(\"subject\",\"object\",\"predicate\")\\\n",
    "    .withColumnRenamed(\"subject\",\"src\").withColumnRenamed(\"object\",\"dst\")\n",
    "    return v, e\n",
    "\n",
    "v, e = vertices_edges_split(df_sub_scien_polit, \"predicate='rdf:type'\")\n",
    "g = GraphFrame(v, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all relationships where a person is both a politican and a scientist\n",
    "motifs = g.find(\"(a)-[]->(b); (a)-[]->(c)\").filter(\"b.id = '<wordnet_scientist_110560637>'and \\\n",
    "                                                    c.id = '<wordnet_politician_110450303>'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7182"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the total number of politicians that are also scientists\n",
    "motifs.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83ldod3AAFk0"
   },
   "source": [
    "The total number of politicians that are also scientists is: 7182"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+-------------------------------+--------------------------------+\n",
      "|person                     |b                              |c                               |\n",
      "+---------------------------+-------------------------------+--------------------------------+\n",
      "|[<A._C._Cuza>]             |[<wordnet_scientist_110560637>]|[<wordnet_politician_110450303>]|\n",
      "|[<A._P._J._Abdul_Kalam>]   |[<wordnet_scientist_110560637>]|[<wordnet_politician_110450303>]|\n",
      "|[<Aad_Kosto>]              |[<wordnet_scientist_110560637>]|[<wordnet_politician_110450303>]|\n",
      "|[<Aad_Nuis>]               |[<wordnet_scientist_110560637>]|[<wordnet_politician_110450303>]|\n",
      "|[<Aaron_Aaronsohn>]        |[<wordnet_scientist_110560637>]|[<wordnet_politician_110450303>]|\n",
      "|[<Aaron_Farrugia>]         |[<wordnet_scientist_110560637>]|[<wordnet_politician_110450303>]|\n",
      "|[<Ab_Klink>]               |[<wordnet_scientist_110560637>]|[<wordnet_politician_110450303>]|\n",
      "|[<Abba_P._Lerner>]         |[<wordnet_scientist_110560637>]|[<wordnet_politician_110450303>]|\n",
      "|[<Abbas_Ahmad_Akhoundi>]   |[<wordnet_scientist_110560637>]|[<wordnet_politician_110450303>]|\n",
      "|[<Abbie_Hoffman>]          |[<wordnet_scientist_110560637>]|[<wordnet_politician_110450303>]|\n",
      "|[<Abbott_Lawrence_Lowell>] |[<wordnet_scientist_110560637>]|[<wordnet_politician_110450303>]|\n",
      "|[<Abdallah_Salem_el-Badri>]|[<wordnet_scientist_110560637>]|[<wordnet_politician_110450303>]|\n",
      "|[<Abdelbaki_Hermassi>]     |[<wordnet_scientist_110560637>]|[<wordnet_politician_110450303>]|\n",
      "|[<Abdellatif_Abid>]        |[<wordnet_scientist_110560637>]|[<wordnet_politician_110450303>]|\n",
      "|[<Abdelouahed_Souhail>]    |[<wordnet_scientist_110560637>]|[<wordnet_politician_110450303>]|\n",
      "|[<Abdelwahed_Radi>]        |[<wordnet_scientist_110560637>]|[<wordnet_politician_110450303>]|\n",
      "|[<Abdesslam_Yassine>]      |[<wordnet_scientist_110560637>]|[<wordnet_politician_110450303>]|\n",
      "|[<Abdi_Farah_Shirdon>]     |[<wordnet_scientist_110560637>]|[<wordnet_politician_110450303>]|\n",
      "|[<Abdirahman_Duale_Beyle>] |[<wordnet_scientist_110560637>]|[<wordnet_politician_110450303>]|\n",
      "|[<Abdiweli_Mohamed_Ali>]   |[<wordnet_scientist_110560637>]|[<wordnet_politician_110450303>]|\n",
      "+---------------------------+-------------------------------+--------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# your code\n",
    "#sort the output alphabetically by the person column.\n",
    "motifs.sort(\"a.id\",ascending=True).withColumnRenamed(\"a\",\"person\").limit(20).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wEOj9sJAFk0"
   },
   "source": [
    "## 2. Companies whose founders were born in London (Question B)\n",
    "For companies, use `'<wordnet_company_108058098>'`. \n",
    "For *\"being founder\"*, use `predicate=<created>`.\n",
    "\n",
    "By now, you will understand which DataFrame to use for what. \n",
    "\n",
    "Set up a graph and use a motif query to find companies whose founders were born in London.\n",
    "Please take some time to figure out how a suitable configuration of nodes and edges should look like.  How many such companies are there in our dataset?\n",
    "\n",
    "Please sort the output alphabetically by the founder column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "GuS4COCqAFk0",
    "outputId": "a0ffbcb3-6e4a-4a1e-98c2-7e51b27a5cdc"
   },
   "outputs": [],
   "source": [
    "# your code\n",
    "\n",
    "#Subset the df_subclasses to get all the subjects that are companies:\n",
    "df_sub_company = spark.sql(\"select subject from df_subclasses where object == '<wordnet_company_108058098>' and predicate='rdf:type'\")\n",
    "df_sub_company.createOrReplaceTempView(\"df_sub_company\")\n",
    "\n",
    "#Subset the df to get all the subjects that are born in London:\n",
    "df_London = spark.sql(\"select * from df where object == '<London>' and predicate =='<wasBornIn>'\")\n",
    "df_London.createOrReplaceTempView(\"df_London\")\n",
    "\n",
    "#Subset the df to get all the relationships that are <created>:\n",
    "df_created = spark.sql(\"select * from df where predicate =='<created>'\")\n",
    "df_created.createOrReplaceTempView(\"df_created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the df get the records where predicate = <created> and object is a company name linked to the df_sub_company\n",
    "df_companies = spark.sql(\"select a.* from df_created as a inner join df_sub_company as b where a.object = b.subject\")\n",
    "df_companies.createOrReplaceTempView(\"df_companies\")\n",
    "\n",
    "#From df_companies get subjects that were born in London\n",
    "df_comp_London= spark.sql(\"select c.subject as founder, \\\n",
    "                            c.object as company, \\\n",
    "                            c.predicate as created, \\\n",
    "                            l.predicate as born \\\n",
    "                            from df_companies c inner join df_London as l \\\n",
    "                            where c.subject = l.subject\")\n",
    "df_comp_London.createOrReplaceTempView(\"df_comp_London\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the graph\n",
    "sub2 = df_comp_London.select(\"founder\").withColumnRenamed(\"founder\",\"id\")\n",
    "obj2 = df_comp_London.select(\"company\").withColumnRenamed(\"company\",\"id\")\n",
    "v2 = sub2.union(obj2).distinct()\n",
    "\n",
    "e2 = df_comp_London.select(\"founder\", \"company\")\\\n",
    ".withColumnRenamed(\"founder\",\"src\").withColumnRenamed(\"company\",\"dst\")\n",
    "#I have set the source to be the company, so that in the output the company appears first, \n",
    "#but based on the yago dataset the founder is conceptually correct to be the source\n",
    "\n",
    "g2 = GraphFrame(v2, e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the motif for companies whose founders were born in London\n",
    "motifs2 = g2.find(\"(a)-[]->(b)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the number of entries in the motif\n",
    "motifs2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the number of companies that are in the motif dataset\n",
    "motifs2.select('b').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LW1xpb2QAFk1"
   },
   "source": [
    "There are only 59 different companies, but 61 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+---------------------------------------+\n",
      "|founder                          |company                                |\n",
      "+---------------------------------+---------------------------------------+\n",
      "|[<Adam_Hamdy>]                   |[<Dare_Comics>]                        |\n",
      "|[<Alexander_Asseily>]            |[<Jawbone_(company)>]                  |\n",
      "|[<Antony_Jay>]                   |[<Video_Arts>]                         |\n",
      "|[<Aubrey_de_Grey>]               |[<SENS_Research_Foundation>]           |\n",
      "|[<Ben_Horowitz>]                 |[<Andreessen_Horowitz>]                |\n",
      "|[<Bernard_MacMahon_(filmmaker)>] |[<LO-MAX_Records>]                     |\n",
      "|[<Brian_Maxwell>]                |[<PowerBar>]                           |\n",
      "|[<Bruno_Heller>]                 |[<Primrose_Hill_Productions>]          |\n",
      "|[<Charlie_Chaplin>]              |[<United_Artists>]                     |\n",
      "|[<Dan_Joyce>]                    |[<Kurrupt_Recordings_HARD>]            |\n",
      "|[<Daniel_James_(game_developer)>]|[<Three_Rings_Design>]                 |\n",
      "|[<David_Harel>]                  |[<I-Logix>]                            |\n",
      "|[<David_Heyman>]                 |[<Heyday_Films>]                       |\n",
      "|[<David_Kimche>]                 |[<Israel_Council_on_Foreign_Relations>]|\n",
      "|[<Demis_Hassabis>]               |[<DeepMind>]                           |\n",
      "|[<Ellen_Browning_Scripps>]       |[<Scripps_Health>]                     |\n",
      "|[<Ellen_Browning_Scripps>]       |[<Luce,_Forward,_Hamilton_&_Scripps>]  |\n",
      "|[<Elliot_James>]                 |[<Blossöm_Records>]                    |\n",
      "|[<Emma_Thomas>]                  |[<Syncopy_Inc.>]                       |\n",
      "|[<Ernest_Webb>]                  |[<Rezolution_Pictures>]                |\n",
      "+---------------------------------+---------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# your code\n",
    "#Sort the output alphabetically by the founder column and show the top 20 results\n",
    "motifs2.sort(\"a.id\", ascending=True).withColumnRenamed(\"a\",\"founder\").withColumnRenamed(\"b\",\"company\").show(20, truncate = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEoKKWjTAFk2"
   },
   "source": [
    "## 3. Writers who have won a Nobel Prize in any discipline, including economics (Question C)\n",
    "Tags for nobel prizes look like these: `'<Nobel_Prize_in_Chemistry>`, `<Nobel_Prize_in_Physics>'`, `<Nobel_Prize>` or `<Nobel_Prize>` etc.\n",
    "We are also counting this one: `'<Nobel_Memorial_Prize_in_Economic_Sciences>'`.\n",
    "\n",
    "The tag for writers is `'<wordnet_writer_110794014>'`.\n",
    "\n",
    "You will need to use `'<hasWonPrize>'` as a predicate.\n",
    "\n",
    "Please sort the output alphabetically by the person column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "bC1i2AQjAFk2",
    "outputId": "58262e0c-e6e5-4a3b-b035-5ab170c108f7"
   },
   "outputs": [],
   "source": [
    "# your code\n",
    "\n",
    "#Get a subset of the df_subset dataframe, where subjects are writers:\n",
    "df_sub_writers = spark.sql(\"select subject from df_subclasses where object == '<wordnet_writer_110794014>' and predicate='rdf:type'\")\n",
    "df_sub_writers.createOrReplaceTempView(\"df_sub_writers\")\n",
    "\n",
    "#From the df get only the records where the subjects are writers\n",
    "df_writers = spark.sql(\"select df.* from df inner join df_sub_writers as w where df.subject = w.subject\")\n",
    "df_writers.createOrReplaceTempView(\"df_writers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the graph where vertices are the people (the writers) and their objects (including the prizes)\n",
    "#Edges are the action that a writer has won a prize\n",
    "v3, e3 = vertices_edges_split(df_writers, \"predicate='<hasWonPrize>'\")\n",
    "g3 = GraphFrame(v3, e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the motif\n",
    "motifs3 = g3.find(\"(a)-[]->(b)\").filter(\"b.id like '%Nobel_Prize%' or b.id == '<Nobel_Memorial_Prize_in_Economic_Sciences>'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+---------------------------------------------+\n",
      "|writer                          |Nobel Prize                                  |\n",
      "+--------------------------------+---------------------------------------------+\n",
      "|[<Adrienne_Clarkson>]           |[<Nobel_Prize_in_Physics>]                   |\n",
      "|[<Albert_Camus>]                |[<Nobel_Prize_in_Literature>]                |\n",
      "|[<Albert_Einstein>]             |[<Nobel_Prize_in_Physics>]                   |\n",
      "|[<Aleksandr_Solzhenitsyn>]      |[<Nobel_Prize_in_Literature>]                |\n",
      "|[<Alexander_Prokhorov>]         |[<Nobel_Prize_in_Physics>]                   |\n",
      "|[<Alexei_Alexeyevich_Abrikosov>]|[<Nobel_Prize_in_Physics>]                   |\n",
      "|[<Alexis_Carrel>]               |[<Nobel_Prize_in_Physiology_or_Medicine>]    |\n",
      "|[<Alfred_Kastler>]              |[<Nobel_Prize_in_Physics>]                   |\n",
      "|[<Alice_Munro>]                 |[<Nobel_Prize_in_Literature>]                |\n",
      "|[<Alvin_E._Roth>]               |[<Nobel_Memorial_Prize_in_Economic_Sciences>]|\n",
      "|[<Alvin_Toffler>]               |[<Nobel_Prize_in_Chemistry>]                 |\n",
      "|[<Amartya_Sen>]                 |[<Nobel_Memorial_Prize_in_Economic_Sciences>]|\n",
      "|[<Anatole_France>]              |[<Nobel_Prize_in_Literature>]                |\n",
      "|[<André_Gide>]                  |[<Nobel_Prize_in_Literature>]                |\n",
      "|[<Arthur_Kornberg>]             |[<Nobel_Prize_in_Physiology_or_Medicine>]    |\n",
      "|[<Aziz_Sancar>]                 |[<Nobel_Prize_in_Chemistry>]                 |\n",
      "|[<Bert_Sakmann>]                |[<Nobel_Prize_in_Physiology_or_Medicine>]    |\n",
      "|[<Bertrand_Russell>]            |[<Nobel_Prize_in_Literature>]                |\n",
      "|[<Bjørnstjerne_Bjørnson>]       |[<Nobel_Prize_in_Literature>]                |\n",
      "|[<Bob_Dylan>]                   |[<Nobel_Prize_in_Literature>]                |\n",
      "+--------------------------------+---------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sort the output alphabetically by the person column\n",
    "motifs3.sort(\"a.id\", ascending=True).withColumnRenamed(\"a\",\"writer\").withColumnRenamed(\"b\",\"Nobel Prize\").show(20, truncate = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the total count of the entries in the motif\n",
    "motifs3.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OZpUAkkAFk2"
   },
   "source": [
    "## 4. Nobel prize winners who were born in the same city as their spouses (Question D)\n",
    "You may find the predicate `'<isMarriedTo>'` useful to create a Dataframe of all mariages.\n",
    "Please also show the cities in which the Nobel laureates and their spouses were born.\n",
    "\n",
    "Please sort the output alphabetically by the person (prize winner) column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code\n",
    "#Get dataframe subsets\n",
    "\n",
    "#Subset the df dataframe df to get Nobel prize winners:\n",
    "df_nobel_winners = spark.sql(\"select df.* from df where predicate='<hasWonPrize>' and \\\n",
    "                            (object like '%Nobel_Prize%' or object = '<Nobel_Memorial_Prize_in_Economic_Sciences>')\")\n",
    "df_nobel_winners.createOrReplaceTempView(\"df_nobel_winners\")\n",
    "\n",
    "#Subset the df dataframe by joining it with the df_nobel_winners to get all the records of Nobel prize winners:\n",
    "df_nobel_winners_all = spark.sql(\"select df.* from df inner join df_nobel_winners as n on df.subject =n.subject\")\n",
    "df_nobel_winners_all.createOrReplaceTempView(\"df_nobel_winners_all\")\n",
    "\n",
    "#Subset the df dataframe of df_nobel_winners_all so that the predicate is '<isMarriedTo>':\n",
    "df_spouses = spark.sql(\"select * from df_nobel_winners_all where predicate='<isMarriedTo>'\")\n",
    "df_spouses.createOrReplaceTempView(\"df_spouses\")\n",
    "\n",
    "df_cities = spark.sql(\"select * from df where predicate =='<wasBornIn>'\")\n",
    "df_cities.createOrReplaceTempView(\"df_cities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create vertices for the writers\n",
    "nobelVerticesWithType = spark.sql(\"select subject as id, 'nobelwinner' as vtype from df_nobel_winners \")\n",
    "\n",
    "#Get both subject and object as the spouce vertex, because both columns have person ids\n",
    "spouseVerticesWithType = spark.sql(\"select object as id, 'spouse' as vtype from df_spouses \")\n",
    "spouseVerticesWithType.createOrReplaceTempView(\"spouseVerticesWithType\")\n",
    "\n",
    "#Create vertices for the birth cities:\n",
    "cityVertices = spark.sql(\"select object as id, 'city' as vtype from df_cities\")\n",
    "cityVertices.createOrReplaceTempView(\"cityVertices\")\n",
    "\n",
    "#union vertices\n",
    "AllVertices = nobelVerticesWithType.union(spouseVerticesWithType).union(cityVertices).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Edges\n",
    "#left is the writer, right is her/his spouse\n",
    "SpouceEdges = df_spouses.select(\"subject\",\"object\",\"predicate\")\\\n",
    "                        .withColumnRenamed(\"subject\",\"src\").withColumnRenamed(\"object\",\"dst\")\n",
    "\n",
    "#left is the person, right is her/his birth city\n",
    "CityEdges = df_cities.select(\"subject\",\"object\",\"predicate\")\\\n",
    "                        .withColumnRenamed(\"subject\",\"src\").withColumnRenamed(\"object\",\"dst\")    \n",
    "    \n",
    "#union edges\n",
    "AllEdges = SpouceEdges.union(CityEdges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the tripartite Graph\n",
    "g4 = GraphFrame(AllVertices,AllEdges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the motif\n",
    "\n",
    "# n: nobel winner vertex\n",
    "# s: spouse vertex\n",
    "# c: city vertex\n",
    "motif4 = g4.find(\"(n)-[e1]->(s);(s)-[e2]->(c);(n)-[e3]->(c)\")\\\n",
    "        .filter(\"e1.predicate ='<isMarriedTo>'\")\\\n",
    "        .filter(\"e2.predicate ='<wasBornIn>'\")\\\n",
    "        .filter(\"e3.predicate ='<wasBornIn>'\")\\\n",
    "        .filter(\"n.id != s.id\")\\\n",
    "        .filter(\"n.vtype = 'nobelwinner'\")\\\n",
    "        .filter(\"s.vtype = 'spouse'\")\\\n",
    "        .filter(\"c.vtype = 'city'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+---------------------------------+-----------------------+\n",
      "|nobel_winner                          |spouse                           |city                   |\n",
      "+--------------------------------------+---------------------------------+-----------------------+\n",
      "|[<Carl_Ferdinand_Cori>, nobelwinner]  |[<Gerty_Cori>, spouse]           |[<Prague>, city]       |\n",
      "|[<Frédéric_Joliot-Curie>, nobelwinner]|[<Irène_Joliot-Curie>, spouse]   |[<Paris>, city]        |\n",
      "|[<Gerty_Cori>, nobelwinner]           |[<Carl_Ferdinand_Cori>, spouse]  |[<Prague>, city]       |\n",
      "|[<Irène_Joliot-Curie>, nobelwinner]   |[<Frédéric_Joliot-Curie>, spouse]|[<Paris>, city]        |\n",
      "|[<Robert_Hofstadter>, nobelwinner]    |[<Douglas_Hofstadter>, spouse]   |[<New_York_City>, city]|\n",
      "+--------------------------------------+---------------------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Show the motif that was created above with selected meaningful column names\n",
    "#The motif shows the top 20 Nobel prize winners with alphabetical order, who were born in the same city as their spouses\n",
    "motif4.sort(\"n.id\", ascending=True)\\\n",
    "      .withColumnRenamed(\"n\",\"nobel_winner\")\\\n",
    "      .withColumnRenamed(\"s\",\"spouse\")\\\n",
    "    .withColumnRenamed(\"c\",\"city\")\\\n",
    "      .select(\"nobel_winner\", \"spouse\", \"city\").show(20, truncate = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the resuls above we understand that for 2 couples both husband and wife received a nobel prize (Carl_Ferdinand_Cori, Gerty_Cori) and (Frédéric_Joliot-Curie, Irène_Joliot-Curie)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the total count of the entries in the motif\n",
    "motif4.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "naDOrDAVAFk3"
   },
   "source": [
    "## 5. Politicians that are affiliated with a right-wing party (Question E)\n",
    "\n",
    "We are looking for all connections of the form `polician -> party`, where party is a right-wing party and politicians are defined above. If one politician is associated with several right wing parties, you may count them several times.\n",
    "\n",
    "Use `'<isAffiliatedTo>'` to find membership in organisations and `'<wikicat_Right-wing_parties>'` for right-wing parties organisations.\n",
    "\n",
    "There are multiple ways to do this.\n",
    "\n",
    "Please sort the output alphabetically by the person (politician) column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code\n",
    "#Create a subset of the df_subclasses, for the right wing parties.\n",
    "df_sub_parties = spark.sql(\"select * from df_subclasses where object == '<wikicat_Right-wing_parties>' and predicate='rdf:type'\")\n",
    "df_sub_parties.createOrReplaceTempView(\"df_sub_parties\")\n",
    "\n",
    "#The df_sub_politician was created on the first question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the df get only the records where the subjects are politicians and the objects parties\n",
    "df_pol_parties = spark.sql(\"select df1.* from (select df.* from df inner join df_sub_politician as pol on df.subject = pol.subject) df1\\\n",
    "                       inner join df_sub_parties as par on df1.object = par.subject\")\n",
    "df_pol_parties.createOrReplaceTempView(\"df_pol_parties\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the graph\n",
    "v5, e5 = vertices_edges_split(df_pol_parties, \"predicate='<isAffiliatedTo>'\")\n",
    "g5 = GraphFrame(v5, e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the motif\n",
    "motif5 = g5.find(\"(a)-[e]->(b)\").filter(\"e.predicate ='<isAffiliatedTo>'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+----------------------------------------+\n",
      "|politician                       |party                                   |\n",
      "+---------------------------------+----------------------------------------+\n",
      "|[<A.N.M._Ehsanul_Hoque_Milan>]   |[<Bangladesh_Nationalist_Party>]        |\n",
      "|[<A._A._Wijethunga>]             |[<United_National_Party>]               |\n",
      "|[<A._B._Colton>]                 |[<Republican_Party_(United_States)>]    |\n",
      "|[<A._C._Clemons>]                |[<Republican_Party_(United_States)>]    |\n",
      "|[<A._C._Gibbs>]                  |[<Republican_Party_(United_States)>]    |\n",
      "|[<A._C._Hamlin>]                 |[<Republican_Party_(United_States)>]    |\n",
      "|[<A._Clifford_Jones>]            |[<Republican_Party_(United_States)>]    |\n",
      "|[<A._Dean_Jeffs>]                |[<Republican_Party_(United_States)>]    |\n",
      "|[<A._F._M._Ahsanuddin_Chowdhury>]|[<Jatiya_Party_(Ershad)>]               |\n",
      "|[<A._G._Crowe>]                  |[<Republican_Party_(United_States)>]    |\n",
      "|[<A._Homer_Byington>]            |[<Republican_Party_(United_States)>]    |\n",
      "|[<A._Homer_Byington>]            |[<National_Union_Party_(United_States)>]|\n",
      "|[<A._J._M._Muzammil>]            |[<United_National_Party>]               |\n",
      "|[<A._J._McNamara>]               |[<Republican_Party_(United_States)>]    |\n",
      "|[<A._J._Ranasinghe>]             |[<United_National_Party>]               |\n",
      "|[<A._K._A._Firoze_Noon>]         |[<Bangladesh_Nationalist_Party>]        |\n",
      "|[<A._K._Patel>]                  |[<Bharatiya_Janata_Party>]              |\n",
      "|[<A._Linwood_Holton_Jr.>]        |[<Republican_Party_(United_States)>]    |\n",
      "|[<A._M._Starr>]                  |[<Republican_Party_(United_States)>]    |\n",
      "|[<A._Piatt_Andrew>]              |[<Republican_Party_(United_States)>]    |\n",
      "+---------------------------------+----------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the top 20 alphabetically politicians that are affiliated with a right-wing party\n",
    "motif5.sort(\"a.id\", ascending=True)\\\n",
    "      .withColumnRenamed(\"a\",\"politician\")\\\n",
    "      .withColumnRenamed(\"b\",\"party\")\\\n",
    "      .select(\"politician\", \"party\").show(20, truncate = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32243"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the total count of the entries in the motif\n",
    "motif5.count()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "hw_yago_local.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
